# CL-Final-Project: Themes in tourist brochures

Research question and data

The object of my final project is to provide an understanding about the representation of Helsinki as a travel destination for English speaking tourists. Therefore, I decided to conduct a LDA topic modelling project where I try to identify themes that appear in texts of tourist brochures. After finding the themes, I want to analyze how do these themes fit together and what kind of story do they tell for visitors.

For this project, I am handling a dataset that contains 30 tourist brochures produced by the city of Helsinki between 1967-2008. The dataset is accessible and can be downloaded from the Language bank of Finland. It contains also visual data, but this time I will analyze only the texts that are found in XML format. The brochures are in English.

Method

To prepare the data for topic modelling, I downloaded the XML files into OpenRefine. There I transformed all the text to lowercase letters by common transform option. Then I removed the punctuation of sentences and replaced it with a space. After this, I split the multi-valued cells that contained multiple words so that each cell had only one word. In this phase, I saw that all the columns of my data didn’t contain information that would be useful for topic modelling. I decided to remove six out of eight columns because those included some abstract metadata like page numbers. Also, I decided to remove all numbers from my data because I thought that those would be difficult to analyze without their specific context. Finally, I exported my data as a CSV document from Openrefine. The rest of the preprocessing was done in Python with several tools.

To execute a topic model, I continued processing the data further. I started to write a Python code in Jupyter notebook. First, I imported few libraries that are needed for processing the data and for building and visualizing topic model with Genism. To recognize the common words from data, I downloaded a Natural language tool kit stopwords. To lemmatize the words, I downloaded Spacy library and to constitute a topic model, I downloaded Gensim library. Because I executed the topic modelling with help of YouTube tutorial that utilized data in JSON form, I converted my CSV file to JSON. Further, I made the Json file “flat” because later during my project I understood that my data was somehow hierarchical and that affected to my results. Then I converted the data from column to string. After preprocessing the data, I created the topic model with Gensim. I knew that the number of topics should be aligned with my data to have good results. I tried few different options and it seemed that eight topics would be somehow reasonable amount for my project. When I raised the number of topics, it became harder to understand what the relation of words inside the topic was. Finally, I made visualization of my results with pyLDAvis tool.

Results

When I look at the results of my project, I must admit that there are several errors. Firstly, in my data, there is unexpectedly large number of words in Finnish. Many of them refers to names of places such as addresses. On the other hand, there is words like “merisatama”, “retkeilymaja” or “kuvataideakatemia”. Those refer probably also for specific locations, but I was surprised that they do not have English name variants that are perhaps easier to understand for a tourist. The issue with Finnish words is the characters ä and ö. It seems that while I was removing the punctuation, I also removed the special characters with accents and some of the words are in very weird form. For example, the sculptor Emil Wikström has become “wikst” and eläintarha “intarha”. This kind of cases are difficult to analyze without close reading the data.

Other error in my project is that I have not cleaned the data enough. The most urging topic in my results is containing words like “www”, “tel”,”pm”, “fri”. I understand why those words appear frequently in tourist brochures, but on the other hand they don’t really tell me anything about the themes. Accordingly, I could say that tourist brochures represent a one kind of text type that contains a lot of information. Perhaps I was expecting it to be more descriptive text that it is. 

Also, my data contains lot of empty values that I tried to remove in Openrefine and in Python. Somehow, I didn’t succeed to do that so I should study this case more closely. I think that the problem has something to do with the data structure. Understanding the structure of data turned out to be the most difficult part of the project for me. My raw data was divided into columns, and it took me a while to understand how an algorithm process this kind of information versus a plain text.

If I try to find something positive out of my project results, I must admit that my own idea of tourist brochures has changed. I was expecting them to contain more marketing language and words that would evoke some inspiration or excitement. In reality, the frequent words like “museum”, “office”, “restaurant” and “beach” don't bring that much semantic meaning for my analysis because they do not describe particularly Helsinki but a tourism in general. In this project I analyzed only the textual data of the tourist brochures. Perhaps the comprehensive semantic message about Helsinki as an interesting tourist destination comes to alive only with the visual data. Therefore, I think that topic modelling was not probably the best method to study this specific corpus. On the other hand, if I had a deeper knowledge about topic modelling and possibilities of programming, maybe the project could be improved and there would be better results of themes. 
